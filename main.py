from spiders.hot_search import get_hot_research
from spiders.get_contents import get_keyword_posts
from processor.db import Database
from processor.postsmodel import search_posts_by_keyword,save_keyword_to_db,save_posts_to_db,get_all_posts,insert_sentiment_to_db
from models.analysis import analyze_sentiment, extract_keywords
from models.visualize import plot_sentiments,generate_wordcloud

def main():
    db= Database()
    keywords= get_hot_research()  # è·å–çƒ­æœå…³é”®è¯
    save_keyword_to_db(db, keywords)  # ä¿å­˜å…³é”®è¯åˆ°æ•°æ®åº“
    print("ğŸ¤–çƒ­æœå…³é”®è¯å·²ä¿å­˜åˆ°æ•°æ®åº“")

    for item in keywords:
        keyword = item['keyword']
        url = item['url']
        print(f"æ­£åœ¨è·å–å…³é”®è¯ '{keyword}' çš„å¸–å­...")
        posts=get_keyword_posts(url, keyword, maxposts=100)
        if posts:
            save_posts_to_db(db, posts)
            print(f"å…³é”®è¯ '{keyword}' çš„'{len(posts)}'ä¸ªå¸–å­å·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚")
    print("æ‰€æœ‰å…³é”®è¯çš„å¸–å­å·²è·å–å®Œæ¯•ã€‚")
    posts=get_all_posts(db)
    print(posts[:3])
    print(f"ğŸ›ç°åœ¨å¯¹{len(posts)}è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚ã€‚ã€‚")
    posts= analyze_sentiment(posts)  # åˆ†ææƒ…æ„Ÿ
    for post in posts:
        insert_sentiment_to_db(db, post['id'], post['sentiment'])
    print("æƒ…æ„Ÿåˆ†æå·²å®Œæˆã€‚")
    posts=extract_keywords(posts)
    print("å…³é”®è¯æå–å·²å®Œæˆã€‚")
    plot_sentiments(posts)  # å¯è§†åŒ–æƒ…æ„Ÿåˆ†æç»“æœ
    generate_wordcloud(posts)  # å¯è§†åŒ–å…³é”®è¯æå–ç»“æœ


    db.close()

if __name__ == "__main__":
    main()
